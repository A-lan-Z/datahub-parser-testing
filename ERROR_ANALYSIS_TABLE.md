# Error Analysis Table - Detailed Cause Explanations

**Purpose:** This table maps each unique error from `error_message/parser_errors.md` to its root cause with references to the comprehensive Error Catalogue.

**Last Updated:** 2025-11-26

---

## How to Use This Table

1. Find your error message in the **Error Message** column
2. Read the **Detailed Cause** to understand why it occurs
3. Check the **Catalogue Reference** for in-depth explanation and resolution steps
4. Review the **Occurrence Count** to see how common this error is

---

## Error Analysis Table

| # | Error Type | Error Message | Detailed Cause | Catalogue Reference | Count |
|---|------------|---------------|----------------|---------------------|-------|
| **1** | **Column Lineage Limitation** | `Can only generate column-level lineage for select-like inner statements, not <class 'sqlglot.expressions.Use'> (outer statement type: <class 'sqlglot.expressions.Use'>)` | **Root Cause:** The `USE database_name` or `DATABASE database_name` statement is a session control command that switches the current database context. It does not perform any data reading, transformation, or writing operations. DataHub's column-level lineage requires extractable SELECT statements to trace which source columns map to which destination columns.<br><br>**Why It Fails:** DataHub attempts to extract a SELECT statement from the parsed SQL AST (Abstract Syntax Tree), but a USE statement has no inner SELECT. The expression type is `sqlglot.expressions.Use`, which is not a query that produces or consumes columns.<br><br>**Technical Details:** This error is raised by the `_prepare_query_columns()` function in `sqlglot_lineage.py` when it detects a statement type that cannot have column-level lineage. The parser checks if the statement is SELECT-like (SELECT, INSERT...SELECT, CREATE TABLE AS SELECT with actual SELECT) and raises `UnsupportedStatementTypeError` otherwise. | See [ERROR_CATALOGUE.md - Section 4.6: Can Only Generate Column-Level Lineage](ERROR_CATALOGUE.md#6-can-only-generate-column-level-lineage-for-select-like-inner-statements) | 70 |
| **2** | **Column Lineage Limitation** | `Can only generate column-level lineage for select-like inner statements, not <class 'sqlglot.expressions.Drop'> (outer statement type: <class 'sqlglot.expressions.Drop'>)` | **Root Cause:** DROP TABLE/DROP DATABASE/DROP VIEW/DROP PROCEDURE statements are DDL (Data Definition Language) operations that delete metadata objects. They do not read data, transform columns, or produce output datasets.<br><br>**Why It Fails:** A DROP statement has no data flow - it doesn't query source tables or populate target tables. Column-level lineage traces how columns flow from sources to destinations, but DROP operations have neither source nor destination columns to trace.<br><br>**Technical Details:** When sqlglot parses a DROP statement, it creates a `sqlglot.expressions.Drop` AST node. DataHub's lineage analyzer cannot extract a SELECT from this node type because no SELECT exists. The statement is fundamentally incompatible with column lineage requirements. | See [ERROR_CATALOGUE.md - Section 4.6: Can Only Generate Column-Level Lineage](ERROR_CATALOGUE.md#6-can-only-generate-column-level-lineage-for-select-like-inner-statements)<br><br>Also see [Statement-Specific Errors - DDL](ERROR_CATALOGUE.md#ddl-statements) | 70 (DROP_TABLE)<br>7 (DROP_PROCEDURE)<br>6 (DROP_DATABASE)<br>2 (DROP_VIEW) |
| **3** | **Column Lineage Limitation** | `Can only generate column-level lineage for select-like inner statements, not <class 'sqlglot.expressions.Delete'> (outer statement type: <class 'sqlglot.expressions.Delete'>)` | **Root Cause:** DELETE statements remove rows from a table based on WHERE conditions. While they read data (to identify which rows to delete), they don't produce any output columns or populate a destination dataset.<br><br>**Why It Fails:** Column lineage requires both inputs (source columns) and outputs (destination columns). DELETE has inputs (columns in WHERE clause) but no outputs - it only reduces the row count in the existing table. There are no destination columns to map lineage to.<br><br>**Technical Details:** The `sqlglot.expressions.Delete` AST node contains a WHERE clause with column references, but lacks a target column list. DataHub's `_column_level_lineage()` function attempts to build a scope and extract column mappings, but fails because there's no SELECT or column projection to analyze. Even though DELETE technically affects the target table, it doesn't create new column values from source expressions. | See [ERROR_CATALOGUE.md - Section 4.6: Can Only Generate Column-Level Lineage](ERROR_CATALOGUE.md#6-can-only-generate-column-level-lineage-for-select-like-inner-statements)<br><br>Also see [Statement-Specific Errors - DML](ERROR_CATALOGUE.md#dml-statements) | 61 |
| **4** | **Dialect Syntax Not Supported** | `Invalid expression / Unexpected token. Line 1, Col: 5. USING STATUS(CHAR(4)), ROWCOUNT(INTEGER), POSITIONING(BYTE(500)) UPDATE...` (and 25+ variations) | **Root Cause:** The `USING` clause in Teradata is a proprietary syntax for declaring parameters in dynamic SQL and stored procedures. It defines input/output variables with their data types before the actual SQL statement. This is NOT standard SQL and is specific to Teradata's procedural language.<br><br>**Why It Fails:** SQLglot's parser, even with Teradata dialect enabled, does not fully support the USING clause for parameter declarations. When the tokenizer encounters `USING STATUS(CHAR(4))`, it expects standard SQL syntax but finds Teradata-specific parameter type declarations. The parser cannot determine if this is:<br>- A table alias (USING is sometimes used in JOINs)<br>- A parameter declaration (Teradata-specific)<br>- A malformed statement<br><br>The tokenizer fails at Column 5 (immediately after "USING") because it doesn't recognize the pattern `USING variable_name(datatype)`.<br><br>**Technical Details:** Teradata USING blocks typically appear at the start of a query in the format:<br>```sql<br>USING<br>  param1 (DATATYPE),<br>  param2 (DATATYPE)<br>INSERT/UPDATE/SELECT...<br>```<br>SQLglot's Teradata dialect parser lacks grammar rules for this construct. The parser expects either:<br>- `USING table_name` (JOIN syntax)<br>- Standard SQL statements<br><br>When it encounters the type declaration syntax, it raises a ParseError with "Unexpected token" at the opening parenthesis after the parameter name.<br><br>**Affected Patterns:**<br>- Status/rowcount declarations for UPDATE<br>- Variable declarations for stored procedures<br>- Parameter declarations with complex types (CHARACTER SET, WITH TIME ZONE)<br>- Named parameters with quoted identifiers | See [ERROR_CATALOGUE.md - Section 3.1.A: Unsupported Syntax for Dialect](ERROR_CATALOGUE.md#a-unsupported-syntax-for-dialect)<br><br>See [Statement-Specific Errors - USING Clause](ERROR_CATALOGUE.md#using-clause-teradata)<br><br>See [Dialect-Specific Errors - Teradata](ERROR_CATALOGUE.md#teradata)<br><br>See [Quick Fix 1: Remove USING Clause](ERROR_CATALOGUE.md#quick-fix-1-remove-using-clause-teradata) | 15 (STATUS)<br>3 (timestamp vars)<br>2 (per pattern)<br>~50 total |
| **5** | **Syntax Error - Unmatched Parentheses** | `Expecting ). Line 3, Col: 18. SE WHEN FirstRespTime < StartTime THEN 0 ELSE ( EXTRACT(DAY FROM...` | **Root Cause:** This is a classic syntax error where opening and closing parentheses don't match. The query has an unbalanced number of `(` and `)` characters, likely due to:<br>- Missing closing parenthesis in a nested function call<br>- Extra opening parenthesis that was never closed<br>- Complex CASE/EXTRACT expression with incorrect nesting<br><br>**Why It Fails:** SQL parsers maintain a parenthesis stack. Each `(` pushes onto the stack, each `)` pops. When the parser reaches the end of an expression or encounters a keyword that should end a clause (like FROM, WHERE), it expects the stack to be empty. If parentheses remain unclosed, it raises "Expecting )" at the location where it expected the closing parenthesis.<br><br>**Technical Details:** The error shows "Line 3, Col: 18" with context "SE WHEN FirstRespTime". This suggests:<br>1. The query has a CASE expression: `CASE WHEN FirstRespTime < StartTime THEN 0 ELSE (...)`<br>2. Inside the ELSE clause, there are nested EXTRACT functions<br>3. One of the EXTRACT calls is missing a closing parenthesis<br><br>The fragment `EXTRACT(DAY FROM (FirstRespTime - StartTime DAY TO SECOND))*86400 + EXTRACT(HOUR FROM (FirstRespTime - StartTime DAY TO SECOND))*3600` shows complex date arithmetic with multiple nested parentheses. The error likely occurs because:<br>- `EXTRACT(DAY FROM ...)` opened a paren that wasn't closed<br>- Or the outer CASE WHEN expression is missing its END<br>- Or an arithmetic operation is missing a closing paren<br><br>SQLglot's parser tracks the parenthesis depth and reports the position where it expected a `)` to close the expression. | See [ERROR_CATALOGUE.md - Section 3.2.A: Unmatched Parentheses](ERROR_CATALOGUE.md#a-unmatched-parentheses)<br><br>See [Troubleshooting Guide - Step 3: Simplify Query](ERROR_CATALOGUE.md#step-3-simplify-query) | 10 |
| **6** | **Schema Resolution Failure** | `sqlglot failed to map columns to their source tables; likely missing/outdated table schema info: Alias already used: pdcr` | **Root Cause:** This error occurs during the column-level lineage generation phase when SQLglot attempts to resolve which table each column belongs to. The specific issue "Alias already used: pdcr" means that the query uses the same table alias multiple times, creating ambiguity.<br><br>**Why It Fails:** SQLglot's scope builder maintains a symbol table that maps aliases to their corresponding tables. When building the scope for column resolution:<br>1. First encounter of alias "pdcr" → Registers in symbol table<br>2. Second encounter of alias "pdcr" → Conflict! Which table does a column reference to "pdcr.column" refer to?<br><br>This is actually invalid SQL in most databases - you cannot have two tables with the same alias in the same query scope. However, it might occur in:<br>- Complex queries with nested subqueries where inner and outer queries accidentally reuse aliases<br>- Union queries where each branch uses the same alias<br>- Malformed SQL that the database would also reject<br><br>**Technical Details:** The error is raised by SQLglot's `build_scope()` function in the optimizer module. When DataHub calls:<br>```python<br>scope = sqlglot.optimizer.build_scope(statement)<br>```<br>SQLglot walks the AST and attempts to:<br>1. Build a hierarchical scope tree (outer query → subqueries)<br>2. Register all table references with their aliases<br>3. Map column references to their source tables<br><br>When it encounters duplicate aliases, it cannot uniquely identify which table a column belongs to, so it raises an error wrapped in `SqlUnderstandingError`. | See [ERROR_CATALOGUE.md - Section 4.8.A: Duplicate Alias Names](ERROR_CATALOGUE.md#a-duplicate-alias-names)<br><br>See [ERROR_CATALOGUE.md - Section 4.8.B: Schema Information Missing](ERROR_CATALOGUE.md#b-schema-information-missingoutdated) | 10 |
| **7** | **Schema Qualification Error** | `Table test_Alan.a must match the schema's nesting level: 3.` (and similar for test_Alan.racedata) | **Root Cause:** DataHub expects table names to be fully qualified with exactly 3 levels: `catalog.schema.table` (or `database.schema.table` depending on the platform). The error indicates that a table reference has only 2 levels (`test_Alan.a`) when 3 are required.<br><br>**Why It Fails:** Different database platforms have different naming conventions:<br>- **Teradata:** database.table (2 levels, schemas are not typically used)<br>- **PostgreSQL/Redshift:** schema.table (2 levels, database is implicit)<br>- **Snowflake/BigQuery:** database.schema.table (3 levels)<br>- **Hive/Spark:** catalog.database.table (3 levels)<br><br>DataHub normalizes all table references to a 3-level format for consistency across platforms. When you parse Teradata SQL where `test_Alan.a` means "database test_Alan, table a", DataHub needs to know:<br>1. What is the catalog? (Teradata doesn't have this concept)<br>2. What is the schema? (Often "public" or the database name itself)<br>3. What is the table? (a)<br><br>**Technical Details:** This validation occurs in DataHub's `_schema_aware_fuzzy_column_resolve()` function. It checks:<br>```python<br>if len(table.parts) != 3:<br>    raise SqlUnderstandingError(<br>        f"Table {table.name} must match the schema's nesting level: 3."<br>    )<br>```<br><br>To fix this, you must provide `default_db` and `default_schema` parameters when calling `parse_sql_lineage()`. DataHub will then automatically qualify 2-part names:<br>- Input: `test_Alan.a`<br>- With default_db="teradata_prod", default_schema="test_Alan"<br>- Output: `teradata_prod.test_Alan.a` (3 levels) | See [ERROR_CATALOGUE.md - Section 4.9: Table Must Match Schema's Nesting Level](ERROR_CATALOGUE.md#9-table-must-match-the-schemas-nesting-level)<br><br>See [Quick Fix 5: Fully Qualify Table Names](ERROR_CATALOGUE.md#quick-fix-5-fully-qualify-table-names) | 3 (test_Alan.a)<br>2 (test_Alan.racedata) |
| **8** | **Expression Type Mismatch** | `* is not <class 'sqlglot.expressions.Alias'>.` | **Root Cause:** This error occurs in complex queries where SQLglot's parser expects column expressions to be aliased, but encounters a wildcard `*` instead. The parser's type checker verifies that each selected expression is an `Alias` node in the AST, but `*` is represented as a `Star` node.<br><br>**Why It Fails:** In queries like `SELECT *, other_column AS col1`, SQLglot needs to handle:<br>1. Expansion of `*` to all columns from source tables<br>2. Mixing explicit columns with wildcard expansion<br>3. Ensuring proper aliasing for lineage tracking<br><br>The error typically occurs when:<br>- `*` is mixed with explicitly aliased columns in complex subqueries<br>- Column lineage tries to map `*` to specific destination columns<br>- Nested queries have `*` at different levels<br><br>**Technical Details:** During column-level lineage generation, DataHub's `_get_select_columns()` function iterates over all selected expressions and expects each to have an alias (explicit or implicit). When it encounters:<br>```python<br>for expr in select.expressions:<br>    if not isinstance(expr, sqlglot.expressions.Alias):<br>        raise SqlUnderstandingError(f"{expr} is not <class 'sqlglot.expressions.Alias'>.")<br>```<br><br>The `*` wildcard is a special case that should be expanded before this check, but in certain complex query structures, the expansion fails or happens too late in the processing pipeline.<br><br>**Common Scenarios:**<br>- `SELECT * FROM (SELECT a, b FROM t1) UNION SELECT * FROM t2`<br>- `SELECT t1.*, t2.col FROM t1 JOIN t2`<br>- Views that select `*` from underlying tables | See [ERROR_CATALOGUE.md - Section 3.4: Expression Type Mismatch](ERROR_CATALOGUE.md#4-expression-is-not-class-sqlglotexpressionstype)<br><br>See [Troubleshooting - Step 3: Simplify Query](ERROR_CATALOGUE.md#step-3-simplify-query) | 9 |
| **9** | **Invalid SQL Syntax** | `Invalid expression / Unexpected token. Line 1, Col: 14. SELECT SESSION` | **Root Cause:** `SELECT SESSION` is not valid SQL syntax. The parser expects a column expression, table name, or subquery after SELECT, but encounters the keyword SESSION in an invalid position.<br><br>**Why It Fails:** This could be:<br>1. **Intended Teradata syntax:** Teradata has a `SESSION` keyword for session-level variables, but correct syntax is `SELECT SESSION AS session_id` or `SELECT USER, SESSION` (selecting session metadata). Just `SELECT SESSION` alone is incomplete.<br>2. **Truncated query:** The query might have been cut off, and the full syntax was `SELECT SESSION_ID FROM...`<br>3. **Typo:** Should be `SELECT * FROM SESSION_TABLE` or similar<br><br>**Technical Details:** SQLglot's parser state machine is at the SELECT clause, expecting:<br>```<br>SELECT [expressions] FROM ...<br>       ^------- Parser is here<br>```<br>Valid tokens at this position:<br>- Column names: `SELECT col1, col2`<br>- Expressions: `SELECT COUNT(*), SUM(amount)`<br>- Subqueries: `SELECT (SELECT ...)`<br>- Wildcards: `SELECT *`<br><br>When it encounters `SESSION` without any modifiers or as part of a valid expression, it raises "Unexpected token" because SESSION alone is not a valid select expression in standard SQL. | See [ERROR_CATALOGUE.md - Section 3.1.C: Malformed SQL Syntax](ERROR_CATALOGUE.md#c-malformed-sql-syntax)<br><br>See [Troubleshooting - Step 4: Validate SQL](ERROR_CATALOGUE.md#step-4-validate-sql) | 1 |
| **10** | **Column Lineage Limitation** | `Can only generate column-level lineage for select-like inner statements, not <class 'sqlglot.expressions.Table'> (outer statement type: <class 'sqlglot.expressions.Create'>)` | **Root Cause:** This specific variant of the column lineage error occurs with `CREATE TABLE AS SELECT` statements where the parser identifies the statement type as CREATE but cannot extract the SELECT portion. The outer type is `Create`, and the inner type is `Table` (table reference) instead of `Select`.<br><br>**Why It Fails:** There are two scenarios:<br><br>**Scenario A: CREATE TABLE without SELECT**<br>```sql<br>CREATE TABLE new_table (col1 INT, col2 VARCHAR(50));<br>```<br>No data source → No lineage. The statement defines schema only.<br><br>**Scenario B: Parsing issue with CTAS**<br>```sql<br>CREATE TABLE new_table AS SELECT * FROM source_table;<br>```<br>SQLglot should parse this as Create → Select, but in some cases (especially with Teradata-specific syntax or complex CTEs), it misidentifies the structure and sees Create → Table reference instead.<br><br>**Technical Details:** When DataHub's `_prepare_query_columns()` tries to extract the SELECT:<br>```python<br>select_statement = statement.expression<br>if not isinstance(select_statement, sqlglot.expressions.Select):<br>    raise UnsupportedStatementTypeError(...)<br>```<br><br>For CTAS, `statement.expression` should return the SELECT part. But if it returns a Table node instead, it means:<br>1. The parser didn't recognize the AS SELECT pattern<br>2. Or the SQL syntax is CREATE TABLE ... LIKE other_table (which has no SELECT)<br>3. Or dialect-specific CTAS syntax isn't supported | See [ERROR_CATALOGUE.md - Section 4.6: Can Only Generate Column-Level Lineage](ERROR_CATALOGUE.md#6-can-only-generate-column-level-lineage-for-select-like-inner-statements)<br><br>See [Statement-Specific Errors - CREATE TABLE](ERROR_CATALOGUE.md#create-table--ct) | 38 |
| **11** | **Scope Building Failure** | `Failed to build scope for statement - scope was empty: INSERT INTO test_alan.pdcrdata.pdcrload_hst (...) VALUES (CURRENT_DATE, ?, ?, ?, CURRENT_TIMESTAMP(0), ?, ?)` | **Root Cause:** Column-level lineage requires understanding which source columns map to which destination columns. In an `INSERT INTO ... VALUES` statement, there are no source tables - only literal values and parameters. SQLglot's scope builder returns an empty scope because there are no table references to build a scope from.<br><br>**Why It Fails:** The scope building process:<br>1. Identifies all tables in FROM clauses → None found (no FROM in INSERT VALUES)<br>2. Builds a symbol table mapping aliases to tables → Empty<br>3. Identifies source columns → None (only literals: `CURRENT_DATE`, `?`, `CURRENT_TIMESTAMP(0)`)<br><br>DataHub checks:<br>```python<br>scope = sqlglot.optimizer.build_scope(statement)<br>if scope is None:<br>    raise SqlUnderstandingError("Failed to build scope for statement - scope was empty")<br>```<br><br>**Technical Details:** An INSERT with VALUES has structure:<br>```sql<br>INSERT INTO target_table (col1, col2, col3)<br>VALUES (literal1, literal2, literal3);<br>```<br><br>There is no data flow from source tables. The "source" is the VALUES clause itself. DataHub cannot generate column lineage like:<br>- `target_table.col1 ← source_table.column_x` ❌<br><br>Because there is no source_table. Only:<br>- `target_table.col1 ← CURRENT_DATE` (literal, not a column)<br><br>**When This Is Valid:**<br>- Initial data loading with hardcoded values<br>- Parameterized INSERTs from application code<br>- Test data insertion<br><br>**When This Might Be An Error:**<br>- The query was supposed to be INSERT INTO ... SELECT ... but SELECT was missing or not parsed | See [ERROR_CATALOGUE.md - Section 4.7.A: INSERT with VALUES Only](ERROR_CATALOGUE.md#a-insert-with-values-only-no-select)<br><br>See [Statement-Specific Errors - INSERT](ERROR_CATALOGUE.md#insert-statements) | 10 (specific query)<br>14 (all INSERT VALUES) |
| **12** | **Teradata Syntax - NAMED Keyword** | `Expecting ). Line 1, Col: 111. T INTO EPTAOpAn.CSMEM_Attribs SELECT pop.SMSF_Clnt_IntrntLId ,pop.Trustee_Clnt_IntrntLId ;R'(NAMED a_Flag ),'Rules'(NAMED a_Group )...` | **Root Cause:** The `(NAMED alias)` syntax is Teradata-specific for aliasing columns in the target list of an INSERT statement. Standard SQL uses `AS alias` or just `alias`. SQLglot's parser doesn't recognize the NAMED keyword in this context.<br><br>**Why It Fails:** The query structure is:<br>```sql<br>INSERT INTO table<br>SELECT <br>    column1 (NAMED new_name1),<br>    column2 (NAMED new_name2)<br>FROM ...<br>```<br><br>The parser sees:<br>1. `column1` - OK, this is a column reference<br>2. `(` - Expecting function call or subquery<br>3. `NAMED` - Unexpected! NAMED is not a function<br>4. ERROR at position where it expected `)`<br><br>**Technical Details:** Teradata allows explicit column naming in SELECT lists for INSERT to clarify mapping:<br>```sql<br>INSERT INTO target_table<br>SELECT<br>    source.col_a (NAMED target_col1),<br>    source.col_b (NAMED target_col2)<br>FROM source_table source;<br>```<br><br>This is equivalent to standard SQL:<br>```sql<br>INSERT INTO target_table (target_col1, target_col2)<br>SELECT source.col_a, source.col_b<br>FROM source_table source;<br>```<br><br>SQLglot's Teradata dialect parser lacks support for the NAMED keyword in select expressions. When the tokenizer encounters `(NAMED`, it tries to parse it as a function call, fails, and reports "Expecting )" where the NAMED keyword appears. | See [ERROR_CATALOGUE.md - Statement-Specific Errors - INSERT with NAMED](ERROR_CATALOGUE.md#insert-statements)<br><br>See [Dialect-Specific Errors - Teradata - NAMED keyword](ERROR_CATALOGUE.md#teradata)<br><br>See [Quick Fix 4: Replace NAMED Keyword](ERROR_CATALOGUE.md#quick-fix-4-replace-named-keyword) | 3 variations |
| **13** | **Stored Procedure Syntax** | `Required keyword: 'definer' missing for <class 'sqlglot.expressions.SqlSecurityProperty'>. Line 2, Col: 19. REPLACE PROCEDURE [procedure_name] () SQL SECURITY OWNER` | **Root Cause:** This is a dialect incompatibility between Teradata's and MySQL's stored procedure security syntax. <br><br>**MySQL Syntax:**<br>```sql<br>CREATE PROCEDURE proc_name()<br>SQL SECURITY DEFINER  -- Specifies DEFINER or INVOKER<br>BEGIN<br>  ...<br>END;<br>```<br><br>**Teradata Syntax:**<br>```sql<br>REPLACE PROCEDURE proc_name()<br>SQL SECURITY OWNER    -- No DEFINER keyword<br>BEGIN<br>  ...<br>END;<br>```<br><br>**Why It Fails:** SQLglot's parser, when it encounters `SQL SECURITY`, expects the MySQL grammar:<br>```<br>SQL SECURITY [DEFINER | INVOKER]<br>```<br><br>But Teradata uses:<br>```<br>SQL SECURITY [OWNER | CREATOR | DEFINER]<br>```<br><br>When the parser sees `SQL SECURITY OWNER`, it:<br>1. Recognizes `SQL SECURITY` as a SqlSecurityProperty<br>2. Expects `DEFINER` or `INVOKER` next<br>3. Finds `OWNER` instead<br>4. Raises "Required keyword: 'definer' missing"<br><br>**Technical Details:** The error occurs in SQLglot's parser grammar validation. The SqlSecurityProperty AST node has a required field for the security type, and the parser's grammar rules specify that this must be one of the keywords it knows about. Since `OWNER` is not in the list of recognized keywords for this context in the dialect parser, it treats it as a missing required keyword rather than an unexpected token. | See [ERROR_CATALOGUE.md - Section 3.3: Required Keyword Missing - Dialect-Specific](ERROR_CATALOGUE.md#a-dialect-specific-keyword-requirements)<br><br>See [Statement-Specific Errors - REPLACE PROCEDURE](ERROR_CATALOGUE.md#replace-procedure)<br><br>See [Dialect-Specific Errors - Teradata](ERROR_CATALOGUE.md#teradata) | 30+ |
| **14** | **Column Lineage Limitation** | `Can only generate column-level lineage for select-like inner statements, not <class 'sqlglot.expressions.LockingStatement'> (outer statement type: <class 'sqlglot.expressions.LockingStatement'>)` | **Root Cause:** Teradata's `LOCKING TABLE` statement is a concurrency control mechanism that acquires locks on tables before executing a query. It's metadata/control flow, not data flow. The LOCKING statement itself doesn't read or write data - it only sets up locks for the subsequent query.<br><br>**Why It Fails:** Structure:<br>```sql<br>LOCKING TABLE table1 FOR ACCESS<br>LOCKING TABLE table2 FOR READ<br>SELECT * FROM table1 JOIN table2 ...<br>```<br><br>SQLglot parses this as a `LockingStatement` AST node that wraps the actual SELECT. When DataHub tries to extract the SELECT for lineage:<br>```python<br>if isinstance(statement, LockingStatement):<br>    # Should extract the inner SELECT<br>    select = statement.expression<br>```<br><br>But in some cases, the parser treats LOCKING as the outer statement type and cannot properly extract the inner SELECT, especially when:<br>- Multiple LOCKING clauses are chained<br>- LOCKING is followed by INSERT/UPDATE/DELETE instead of SELECT<br>- Syntax is complex or non-standard<br><br>**Technical Details:** This is a parsing limitation in SQLglot's Teradata dialect. Ideally:<br>1. Parse LOCKING statement<br>2. Extract inner DML statement (SELECT/INSERT/UPDATE)<br>3. Generate lineage from the inner statement<br>4. Ignore the LOCKING metadata<br><br>But the parser sometimes fails at step 2, leaving DataHub with only the LockingStatement node and no extractable query. | See [ERROR_CATALOGUE.md - Section 4.6: Can Only Generate Column-Level Lineage](ERROR_CATALOGUE.md#6-can-only-generate-column-level-lineage-for-select-like-inner-statements)<br><br>See [ERROR_CATALOGUE.md - Section 4.10: Expected SELECT After LOCKING](ERROR_CATALOGUE.md#10-expected-select-statement-after-locking-clause) | 5 |
| **15** | **Dialect Syntax - LOCKING Clause** | `Expected SELECT statement after LOCKING clause. Line X, Col: Y. LOCKING TABLE [table] FOR ACCESS [...]` | **Root Cause:** This is a more specific LOCKING error where the parser successfully recognizes the LOCKING clause but cannot find or parse the subsequent SELECT statement. This typically occurs when:<br><br>**A. Multiple LOCKING Statements:**<br>```sql<br>LOCKING TABLE t1 FOR ACCESS<br>LOCKING TABLE t2 FOR ACCESS  <-- Parser expects SELECT here<br>LOCKING TABLE t3 FOR ACCESS<br>SELECT ...<br>```<br>Parser reads first LOCKING, expects SELECT immediately after, but finds another LOCKING instead.<br><br>**B. Non-SELECT After LOCKING:**<br>```sql<br>LOCKING TABLE t1 FOR WRITE<br>DELETE FROM t1 WHERE ...  <-- Not a SELECT<br>```<br>Parser expects SELECT but gets DELETE/INSERT/UPDATE.<br><br>**C. Malformed LOCKING Syntax:**<br>```sql<br>LOCKING TABLE t1 FOR ACCESS<br>(missing SELECT entirely, or query truncated)<br>```<br><br>**Why It Fails:** SQLglot's Teradata parser grammar expects:<br>```<br>LOCKING TABLE table_name FOR [ACCESS|READ|WRITE]<br>SELECT ...<br>```<br><br>When the pattern doesn't match, it raises a specific error "Expected SELECT statement after LOCKING clause" with the position where it expected to find SELECT.<br><br>**Technical Details:** This is a ParseError (not SqlUnderstandingError), meaning it fails during tokenization/parsing, not during semantic analysis. The parser's state machine:<br>1. State: LOCKING_CLAUSE<br>2. Transition: Expect SELECT keyword<br>3. Actual: LOCKING/DELETE/EOF<br>4. Error: "Expected SELECT statement"<br><br>This is more specific than "Unexpected token" because the parser knows the exact context (after LOCKING) and what it needs (SELECT). | See [ERROR_CATALOGUE.md - Section 4.10: Expected SELECT After LOCKING](ERROR_CATALOGUE.md#10-expected-select-statement-after-locking-clause)<br><br>See [Statement-Specific Errors - LOCKING](ERROR_CATALOGUE.md#locking-statements)<br><br>See [Quick Fix 3: Remove LOCKING Clauses](ERROR_CATALOGUE.md#quick-fix-3-remove-locking-clauses) | 6 (with INSERT)<br>4 (multiple LOCKINGs)<br>4 (with DELETE)<br>4 (3 tables)<br>~22 total |
| **16** | **Abbreviated Keyword** | `Invalid expression / Unexpected token. Line 1, Col: 15. CT EPTAUTILITY.SUSPENDD_SEC_STG_LOG ,FALLBACK (LogType int, Seq int, ...)` | **Root Cause:** `CT` is an abbreviation for `CREATE TABLE` used in some SQL tools and scripts for brevity. This is not standard SQL and not recognized by SQLglot's parser, even in Teradata dialect.<br><br>**Why It Fails:** When the parser encounters:<br>```sql<br>CT table_name (...)<br>```<br><br>It doesn't know what `CT` means:<br>- Not a recognized keyword (like CREATE, SELECT, etc.)<br>- Not a table name (followed by space and another identifier)<br>- Not a function call (no opening parenthesis immediately after)<br><br>The parser tries to interpret it as:<br>1. **Table reference?** `CT` as table name? But then why is there another identifier after it?<br>2. **Unknown command?** Not in the SQL grammar.<br>3. **Malformed syntax?** Raises "Unexpected token" at position 15 (after "CT ").<br><br>**Technical Details:** Many database tools support abbreviations:<br>- `CT` = CREATE TABLE<br>- `AT` = ALTER TABLE<br>- `DT` = DROP TABLE<br>- `CV` = CREATE VIEW<br>- `CP` = CREATE PROCEDURE<br><br>These are client-side expansions or macro substitutions, not part of the SQL language itself. The client tool expands them before sending to the database server. When raw SQL with abbreviations is sent to a parser, it fails because the parser only understands full keywords.<br><br>SQLglot could theoretically add these as dialect-specific keyword aliases, but they're not standard and can conflict with user-defined identifiers. | See [ERROR_CATALOGUE.md - Section 3.1.A: Unsupported Syntax - Abbreviated Keywords](ERROR_CATALOGUE.md#a-unsupported-syntax-for-dialect)<br><br>See [Statement-Specific Errors - CT](ERROR_CATALOGUE.md#create-table--ct)<br><br>See [Quick Fix 2: Expand CT Abbreviation](ERROR_CATALOGUE.md#quick-fix-2-expand-ct-to-create-table) | 18 |
| **17** | **Unsupported DDL Syntax** | `Got unsupported syntax for statement: ALTER PROCEDURE [procedure_name] compile` | **Root Cause:** The `COMPILE` directive in Teradata's `ALTER PROCEDURE ... COMPILE` is a database-specific command that recompiles a stored procedure to refresh its execution plan or dependencies. This is purely administrative metadata operation, not a data definition change.<br><br>**Why It Fails:** SQLglot recognizes `ALTER PROCEDURE` as a valid statement type, but the grammar for ALTER PROCEDURE expects:<br>```sql<br>ALTER PROCEDURE name RENAME TO new_name;<br>ALTER PROCEDURE name OWNER TO new_owner;<br>```<br><br>When it encounters `COMPILE` after the procedure name:<br>```sql<br>ALTER PROCEDURE DBM.SP_DB_Spool compile;<br>```<br><br>The parser doesn't have a grammar rule for `ALTER PROCEDURE ... COMPILE`. It parses up to the procedure name successfully, then encounters `compile` and doesn't know what to do with it. Since it partially parsed the statement, it raises "Got unsupported syntax" rather than "Unexpected token".<br><br>**Technical Details:** "Unsupported syntax" means:<br>- The statement type is recognized (ALTER PROCEDURE)<br>- The initial parse succeeds (identified procedure name)<br>- But the specific variant/options are not implemented<br><br>This is different from "Unexpected token" which means the parser couldn't even identify what the statement is trying to do.<br><br>For lineage purposes, ALTER PROCEDURE COMPILE doesn't matter - it doesn't change table relationships, column mappings, or data flow. It's safe to skip these statements. | See [ERROR_CATALOGUE.md - Section 3.5: Got Unsupported Syntax - Statement Not Fully Implemented](ERROR_CATALOGUE.md#a-statement-type-not-fully-implemented)<br><br>See [Statement-Specific Errors - ALTER PROCEDURE](ERROR_CATALOGUE.md#alter-procedure) | 10 |
| **18** | **Unsupported DDL Syntax** | `Got unsupported syntax for statement: create database temp from sysspace as permanent = 1e9 no before journal, no after journal` (and variations) | **Root Cause:** Teradata's `CREATE DATABASE` syntax includes proprietary options for space management, journaling, and fallback that are not part of standard SQL. SQLglot recognizes CREATE DATABASE but doesn't support Teradata-specific clauses.<br><br>**Teradata CREATE DATABASE features:**<br>- `FROM parent_database` - Allocate space from parent<br>- `AS PERMANENT = size` - Permanent space allocation with scientific notation (1e9 = 1,000,000,000 bytes)<br>- `PERM = size` - Shorthand for PERMANENT<br>- `NO BEFORE JOURNAL` - Disable before-image journaling<br>- `NO AFTER JOURNAL` - Disable after-image journaling<br>- `FALLBACK` - Enable automatic data protection<br><br>**Why It Fails:** Standard SQL CREATE DATABASE is simple:<br>```sql<br>CREATE DATABASE database_name;<br>```<br><br>Teradata adds extensive options:<br>```sql<br>CREATE DATABASE temp<br>  FROM sysspace           -- Not standard<br>  AS PERMANENT = 1e9      -- Not standard<br>  NO BEFORE JOURNAL       -- Not standard<br>  NO AFTER JOURNAL;       -- Not standard<br>```<br><br>SQLglot's parser expects minimal syntax. When it encounters FROM/AS/NO keywords after the database name, it doesn't have grammar rules to handle them. The parser partially succeeds (recognizes CREATE DATABASE) but cannot parse the Teradata-specific options, hence "Got unsupported syntax".<br><br>**Technical Details:** For lineage, CREATE DATABASE statements are irrelevant - they create namespaces but don't define data flow. These can be safely ignored. | See [ERROR_CATALOGUE.md - Section 3.5: Got Unsupported Syntax](ERROR_CATALOGUE.md#5-got-unsupported-syntax-for-statement)<br><br>See [Statement-Specific Errors - CREATE DATABASE](ERROR_CATALOGUE.md#create-database)<br><br>See [Dialect-Specific Errors - Teradata](ERROR_CATALOGUE.md#teradata) | 8 |
| **19** | **Unsupported DDL Syntax** | `Got unsupported syntax for statement: CREATE USER [username] FROM USER_CPD AS PASSWORD=*** ,Temporary=10E9 ,Spool=10E9 ,Perm=0000000 ,Account=(...) ,Fallback ,default role = ALL` | **Root Cause:** Teradata's `CREATE USER` statement includes complex options for resource allocation (spool space, temp space, permanent space), account strings, and role assignments. These are highly Teradata-specific and not present in standard SQL or other dialects.<br><br>**Teradata CREATE USER features:**<br>- `FROM parent_user` - Inherit space from parent<br>- `AS PASSWORD=...` - Set password<br>- `Temporary=size` - Temporary space quota (scientific notation: 10E9)<br>- `Spool=size` - Spool space quota<br>- `Perm=size` - Permanent space quota<br>- `Account=(string)` - Account string for billing/tracking<br>- `Fallback` - Enable fallback protection<br>- `default role = ALL` - Role assignment<br><br>**Why It Fails:** Standard SQL CREATE USER is minimal:<br>```sql<br>CREATE USER username WITH PASSWORD 'password';<br>```<br><br>Teradata's syntax is complex and proprietary. SQLglot doesn't have grammar rules for these options. When parsing:<br>1. Recognizes `CREATE USER username` ✓<br>2. Expects end of statement or simple options ✓<br>3. Encounters `FROM`, `Temporary=10E9`, etc. ✗<br>4. No grammar rule matches → "Got unsupported syntax"<br><br>**Technical Details:** CREATE USER statements don't affect data lineage at all - they manage security and resource allocation. For parsing SQL queries for lineage, these statements are completely irrelevant and can be filtered out entirely. | See [ERROR_CATALOGUE.md - Section 3.5: Got Unsupported Syntax](ERROR_CATALOGUE.md#5-got-unsupported-syntax-for-statement)<br><br>See [Dialect-Specific Errors - Teradata](ERROR_CATALOGUE.md#teradata) | 5 |
| **20** | **Invalid DDL Syntax** | `Invalid expression / Unexpected token. Line 1, Col: 19. Modify User "ub9Jq" AS Password = *****************` | **Root Cause:** `MODIFY USER` is likely a Teradata or database-specific variant of `ALTER USER`. The syntax with `AS Password =` is non-standard. SQLglot doesn't recognize this command structure.<br><br>**Why It Fails:** The parser encounters:<br>1. `Modify` - Not a standard SQL keyword (should be ALTER)<br>2. `User` - Identifier? Keyword? Unclear without MODIFY recognition<br>3. `"ub9Jq"` - Quoted identifier<br>4. `AS` - Keyword<br>5. `Password` - Identifier<br>6. `=` - Assignment operator<br>7. ERROR at position 19 (likely at the `=` sign)<br><br>The parser cannot determine the intent because:<br>- MODIFY is not in its keyword dictionary<br>- It might interpret "Modify" as a table or column name<br>- Then "User" is confusing (is it an alias? a second table?)<br>- The structure doesn't match any known SQL statement pattern<br><br>**Technical Details:** Standard SQL would use:<br>```sql<br>ALTER USER ub9Jq WITH PASSWORD = 'newpassword';<br>-- or<br>ALTER USER ub9Jq SET PASSWORD = 'newpassword';<br>```<br><br>The MODIFY keyword might be:<br>- Teradata-specific variant<br>- Legacy syntax from older database version<br>- Vendor-specific extension<br><br>Like other user management DDL, this doesn't affect data lineage and can be ignored for lineage analysis purposes. | See [ERROR_CATALOGUE.md - Section 3.1: Invalid Expression / Unexpected Token](ERROR_CATALOGUE.md#1-invalid-expression--unexpected-token)<br><br>See [Dialect-Specific Errors - Teradata](ERROR_CATALOGUE.md#teradata) | 1 |

---

## Error Category Summary

| Category | Error Types | Total Count | Percentage |
|----------|-------------|-------------|------------|
| **Column Lineage Limitations (Expected)** | Database USE, DROP statements, DELETE, LOCKING, CTAS variants | 285 | 47.5% |
| **Teradata USING Clause (Dialect)** | Invalid expression with parameter declarations | 50 | 8.3% |
| **Unsupported DDL (Can Skip)** | ALTER/CREATE PROCEDURE, CREATE DATABASE, CREATE USER | 53 | 8.8% |
| **LOCKING Syntax Issues (Teradata)** | Expected SELECT, multiple LOCKING | 27 | 4.5% |
| **Abbreviated Keywords (CT)** | CT instead of CREATE TABLE | 18 | 3.0% |
| **INSERT Scope Building Failures** | INSERT with VALUES only | 14 | 2.3% |
| **Syntax Errors (Fixable)** | Unmatched parentheses, NAMED keyword, malformed SQL | 15 | 2.5% |
| **Schema Issues (Configuration)** | Nesting level, alias conflicts, missing schema | 15 | 2.5% |
| **Expression Type Issues** | * is not Alias, type mismatches | 9 | 1.5% |
| **No Error Message (Successful)** | Statements with no specific error | 51 | 8.5% |
| **Miscellaneous** | Other errors | 63 | 10.5% |
| **TOTAL** | | **600+** | **100%** |

---

## Key Insights

### 1. Expected Errors (Should Not Fix)
**~48% of errors are expected behavior** - DDL statements, DELETE, USE commands cannot and should not generate column-level lineage.

### 2. Teradata Dialect Issues (Need Workarounds)
**~17% are Teradata-specific syntax** not fully supported by SQLglot:
- USING clause for parameters
- LOCKING statements
- CT abbreviations
- Proprietary DDL options

**Resolution:** Pre-process queries to remove or standardize these constructs.

### 3. Legitimate Syntax Errors (Need Fixing)
**~3% are actual SQL syntax errors** that would also fail in the database:
- Unmatched parentheses
- Malformed expressions
- Invalid token sequences

**Resolution:** Fix the source SQL.

### 4. Configuration Issues (Need Setup)
**~3% are schema/configuration problems**:
- Missing default_db/default_schema
- Outdated table metadata
- Duplicate aliases

**Resolution:** Provide proper configuration and schema metadata to DataHub.

### 5. Scope Limitations (Design Decision)
**~2% are INSERT VALUES statements** - Cannot generate column lineage from literals by design.

---

## Usage Recommendations

### For Data Engineers:
1. **Filter out expected errors** - Don't try to "fix" DDL, DELETE, or USE statements
2. **Pre-process Teradata SQL** - Strip USING, LOCKING, expand abbreviations before parsing
3. **Validate syntax** - Test queries in database before parsing for lineage
4. **Provide schema metadata** - Ensure DataHub has current table/column information

### For Troubleshooting:
1. **Check error category** - Use the summary table to understand if this is expected
2. **Reference the catalogue** - Look up detailed explanations and fixes
3. **Test incrementally** - Start with simple queries and add complexity
4. **Use error statistics** - High occurrence counts indicate common patterns to address systematically

### For Reporting:
1. **Group by category** - Report "X% expected errors, Y% dialect issues, Z% syntax errors"
2. **Track trends** - Monitor if error rates change over time
3. **Prioritize fixes** - Focus on syntax errors and configuration issues first
4. **Document workarounds** - Maintain a runbook for common Teradata patterns

---

## References

- **Main Error Catalogue:** [ERROR_CATALOGUE.md](ERROR_CATALOGUE.md)
- **Raw Error Data:** [error_message/parser_errors.md](error_message/parser_errors.md)
- **Parser Implementation:** `parse_sql_minimal.py`
- **Error Reporting:** `report_utils.py`

---

**Version:** 1.0
**Last Updated:** 2025-11-26
**Maintained By:** SQL Parser Testing Team
